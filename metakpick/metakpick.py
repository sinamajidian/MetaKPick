

import argparse
import sys
import os
import logging
import pandas as pd
import numpy as np
import random
np.random.seed(42)
import _training
#from _utils_tree import parse_tree_file, find_tax2root
import _utils_tree
import _utils_kraken

# import matplotlib.pyplot as plt
# import seaborn as sns

# import pickle
# from collections import Counter
# import random

np.random.seed(42)



def main():




    # parser = argparse.ArgumentParser(description='Metakpick: for metagenomic classification of reads')
    # # Main operation mode arguments
    # mode_group = parser.add_mutually_exclusive_group(required=True)
    # mode_group.add_argument('--train', action='store_true', help='Run the training of the model')
    # mode_group.add_argument('--classify', action='store_true', help='Run the classification of the model')
    # parser.add_argument('--reads', type=str, help='Input reads file')
    # parser.add_argument('--output', type=str, help='Output file')
    # parser.add_argument('--model', type=str, help='Model file')
    # parser.add_argument('--threads', type=int, help='Number of threads')

    
    workingdir="/vast/blangme2/smajidi5/metagenomics/metakpick_project/MetaKPick/"
    in_folder= workingdir+"../files/"
    tree_file=in_folder+"nodes.dmp"
    tax_genome_file= in_folder + "seqid2taxid.map_tax_uniq"

    info, Tree, tax_index, tax_genome, parents, tree_df = _utils_tree.get_tax_info(tree_file,tax_genome_file)    
    tax2path, tax2depth = _utils_tree.get_tax2path(tax_genome, info, parents)



    mode="train"
    if mode=="train":

        folder_input =workingdir+"../../changek/simulatation/"
        truth_file=folder_input+"true_tax.csv" # generated by generate_training.ipynb
        classification_folder=folder_input+"classification/" 
        cases=[i.split("_")[0] for i in os.listdir(classification_folder) if i.endswith('_out')] #["k"+str(k) for k in range(15,32)]
        cases=cases[-2:]
        merged  = _utils_kraken.read_kraken_classification(cases, truth_file, classification_folder )
        read_tax_depth = _utils_kraken.get_tax_depth(merged,cases, info,parents)
        # todo: get the read set first, then 
        num_max=2
        merged2a, readids_max = _utils_kraken.limit_read_per_genome(merged,num_max)
        read_names_list=list(readids_max)
        #cases_dic = _utils_kraken.def_cal(dfmerged_taxa,info,tree_df,parents,tax_level,col_name,tax_index)
        case_dic_all, true_k  =  _utils_kraken.find_true_ksize(cases,merged2a,info,tree_df,parents,tax_index, readids_max, level='species')
        dic_cases, cases_readids = _training.read_kraken_all(cases, classification_folder, readids_max)
        features = _training.get_features_all(read_names_list, tax2path, dic_cases, cases, read_tax_depth, tax2depth, info, parents, classification_folder)
        print(len(features))
        
        regr_dic,read_k_prob = _training.train_RF_model_all(cases, features, true_k,read_names_list) 
        print(regr_dic)
        best_k_dic,estimated_tax_dict =_training.get_best_tax(read_k_prob,cases,read_names_list,merged,thr_minprob=0.5)

    elif mode=="classify":
        pass  



if __name__ == "__main__":
    main()
